---
alwaysApply: false
description: How to start and stop the Sibyl server and all services
---

# Server Startup Guide

This rule documents how to boot up all Sibyl services (database, redis, backend API, and frontend).

## Prerequisites

- Docker and Docker Compose must be installed and running
- OpenRouter API key configured in `.env` file (required for AI agents)

## Quick Start - Full Stack

To start all services (recommended):

```bash
cd /Users/abeerdas/Documents/GitHub/Sibyl
docker-compose up -d
```

This will start:
- **PostgreSQL** (with pgvector) on port 5435
- **Redis** on port 6380
- **Backend API** on port 8000
- **Frontend** on port 5173

## Checking Service Status

```bash
cd /Users/abeerdas/Documents/GitHub/Sibyl
docker-compose ps
```

All services should show as "Up" and healthy.

## Viewing Logs

View all logs:
```bash
docker-compose logs -f
```

View specific service logs:
```bash
docker-compose logs -f backend
docker-compose logs -f frontend
docker-compose logs -f db
docker-compose logs -f redis
```

## Stopping Services

Stop all services:
```bash
cd /Users/abeerdas/Documents/GitHub/Sibyl
docker-compose down
```

Stop services and remove volumes (clears database):
```bash
docker-compose down -v
```

## Troubleshooting

### Adding New npm Packages (Frontend)

The frontend uses a Docker anonymous volume to hold `node_modules` (see `docker-compose.yml` lines 56-57). This volume is created once and **persists across restarts** — so a plain `docker-compose up -d --build` will NOT install new packages because the old anonymous volume shadows the freshly built image.

**Whenever a new npm package is added to `frontend/package.json`, use this sequence:**

```bash
cd /Users/abeerdas/Documents/GitHub/Sibyl

# 1. Stop and fully remove the frontend container (destroys the stale anonymous volume)
docker-compose stop frontend && docker-compose rm -f frontend

# 2. Rebuild the image from scratch (no cache, runs npm install fresh)
docker-compose build --no-cache frontend

# 3. Start with --renew-anon-volumes so the volume is repopulated from the new image
docker-compose up -d --renew-anon-volumes frontend
```

**Verify the package is installed:**
```bash
docker exec sibyl-frontend-1 ls /app/node_modules | grep <package-name>
```

**Why this happens:**
- `docker-compose.yml` mounts `./frontend:/app` (live code sync) and shields `node_modules` with an anonymous volume `/app/node_modules`
- The anonymous volume is populated from the image on first creation, then frozen
- `--build` rebuilds the image but reuses the existing volume — the new `node_modules` never lands in the container
- `--renew-anon-volumes` forces the volume to be recreated from the current image

**Also ensure `frontend/.dockerignore` exists** (prevents local `node_modules` from overwriting the container's):
```
node_modules
.env
.env.local
dist
```

### Port Conflicts

If you encounter "port already allocated" errors:

1. Check what's using the port:
   ```bash
   lsof -i :6380  # Redis
   lsof -i :5435  # PostgreSQL
   lsof -i :8000  # Backend
   lsof -i :5173  # Frontend
   ```

2. Stop conflicting Docker containers:
   ```bash
   docker ps -a | grep redis
   docker stop <container-name>
   ```

3. Common conflicts in this workspace:
   - Port 5435: PostgreSQL (changed from 5434 to avoid conflict with Spellbook's SpiceDB on 5434)
   - Port 6380: Redis (changed from 6379 to avoid conflict with Spellbook's Redis on 6379)

### CORS Errors (File Upload Issues)

If you encounter CORS errors like:
```
Access to fetch at 'http://localhost:8000/api/v1/upload' from origin 'http://localhost:5173' 
has been blocked by CORS policy: No 'Access-Control-Allow-Origin' header is present
```

**Cause**: The backend CORS middleware is not configured correctly or needs to be rebuilt.

**Solution**:
1. Verify CORS configuration in `backend/app/main.py` includes:
   ```python
   app.add_middleware(
       CORSMiddleware,
       allow_origins=settings.CORS_ORIGINS,  # ["http://localhost:5173"]
       allow_credentials=True,
       allow_methods=["*"],
       allow_headers=["*"],
       expose_headers=["*"],  # Important!
   )
   ```

2. Rebuild and restart the backend:
   ```bash
   cd /Users/abeerdas/Documents/GitHub/Sibyl
   docker-compose up -d --build backend
   ```

3. Test CORS is working:
   ```bash
   curl -i -X OPTIONS http://localhost:8000/api/v1/upload \
     -H "Origin: http://localhost:5173" \
     -H "Access-Control-Request-Method: POST"
   ```
   Should see `access-control-allow-origin: http://localhost:5173` in response.

### Database Connection Issues

If backend health check shows `"database": "disconnected"`:

1. Restart all services to fix Docker networking:
   ```bash
   docker-compose down && docker-compose up -d
   ```

2. Check database logs:
   ```bash
   docker-compose logs db
   ```

3. Verify database is healthy:
   ```bash
   docker-compose ps
   # Look for "(healthy)" status on db service
   ```

## Service URLs

Once running, access the services at:

| Service    | URL                          |
|------------|------------------------------|
| Frontend   | http://localhost:5173        |
| Backend    | http://localhost:8000        |
| API Docs   | http://localhost:8000/docs   |
| PostgreSQL | localhost:5435               |
| Redis      | localhost:6380               |

## Development Mode (Alternative)

To run services individually for development:

### Backend Only:
```bash
cd backend
pip install -r requirements.txt
uvicorn app.main:app --reload
```
Note: Requires PostgreSQL and Redis already running.

### Frontend Only:
```bash
cd frontend
npm install
npm run dev
```
Note: Requires backend already running.

## Architecture

The docker-compose configuration manages:
- **db**: PostgreSQL 17 with pgvector extension for vector embeddings
- **redis**: Redis 7 for caching and task queues
- **backend**: FastAPI server with LangGraph agents
- **frontend**: React + Vite + TypeScript SPA

Services have health checks and dependency ordering to ensure proper startup sequence.

## Analysis Pipeline & Data Flow

### How Claims and Agent Findings Work

1. **Upload PDF** → Creates a Report record, triggers PDF parsing
2. **Start Analysis** → POST to `/api/v1/analysis/{report_id}/start`
   - Extracts claims from the PDF (Claims Agent)
   - Routes claims to specialist agents (Orchestrator)
   - Agents investigate and create Findings
   - Judge validates and creates Verdicts
3. **View Results**:
   - Claims: GET `/api/v1/analysis/{report_id}/claims`
   - Findings: GET `/api/v1/analysis/{report_id}/findings`
   - Claim + Findings: GET `/api/v1/analysis/{report_id}/claims/{claim_id}/findings`

### Why You Might Not See Claims/Findings

**Problem**: Claims panel shows 0 claims, or no agent investigation results visible

**Possible Causes**:

1. **Analysis Not Started**
   - Upload completes, but analysis doesn't auto-start
   - Solution: Manually click "Start Analysis" in the UI, or POST to the start endpoint
   
2. **Analysis Still Running**
   - Check the "Agent Activity" tab to see pipeline progress
   - Claims extraction can take 2-5 minutes for large PDFs
   - Full pipeline (with agents) can take 5-15 minutes
   
3. **Analysis Failed**
   - Check backend logs: `docker-compose logs backend | grep -i error`
   - Common issues:
     - Missing OpenRouter API key (set in `.env`)
     - Missing Tavily API key (optional, for news/academic agents)
     - Database connection issues
     - Out of OpenRouter credits
   
4. **RAG Corpus Not Ingested**
   - Legal agent needs IFRS/SASB standards in database
   - Check corpus stats: GET `/api/v1/rag/stats`
   - Ingest corpus: POST `/api/v1/rag/ingest` (see FRD-1)
   
5. **Frontend Not Fetching Findings**
   - Findings endpoints were recently added
   - Frontend may need updates to call new `/findings` endpoints
   - Check browser console for API errors

### Debugging Analysis Issues

Check if analysis is running:
```bash
curl -s http://localhost:8000/api/v1/analysis/{report_id}/status | python3 -m json.tool
```

Check if claims exist:
```bash
curl -s "http://localhost:8000/api/v1/analysis/{report_id}/claims?size=5" | python3 -m json.tool
```

Check if findings exist:
```bash
curl -s "http://localhost:8000/api/v1/analysis/{report_id}/findings?size=5" | python3 -m json.tool
```

View backend logs in real-time:
```bash
docker-compose logs -f backend
```

Connect to SSE stream (see agent progress):
```bash
curl -N http://localhost:8000/api/v1/stream/{report_id}
```
